library(shiny)
#install.packages("shinydashboard")
library(shinydashboard)
install.packages("ECharts2Shiny")
#libraries 
library(tidyverse)
library(modelr)
library(lubridate) # for date and time
library(caTools) # library used for splitting the dataset


shinyUI(
  dashboardPage( title ="Group 4 - Teleco Customer Churn", skin = "green",
    dashboardHeader(title = "Customer churn - Group 4"),
    dashboardSidebar(
      sidebarMenu(
      menuItem("Project Information",tabName = "General"),  
      menuItem("Data Exploration",tabName = "dashboard"),
      menuItem("Correlation and Plots",tabName = "diagram"),
      menuItem("Cost Assumption",tabName="cost"),
      menuItem("Model 1 - Logistic Regression",tabName = "Model1"),
      menuItem("Model 2 - K Nearest Neighbors",tabName = "Model2"),
      menuItem("Model 3 - Tree Based Methods",tabName = "Model3"),
        menuSubItem("Model 3a- Decision Trees", tabName = "Model3a"),
        menuSubItem("Model 3b- Random Forest", tabName = "Model3b"),
      menuItem("Model 4 - Discriminant Analysis",tabName = "Model4"),
        menuSubItem("Model 4a - LDA",tabName = "Model4a"),
        menuSubItem("Model 4b - QDA",tabName = "Model4b"),
      menuItem("Model 5 - Naive Bayes", tabName = "Model5"),
      menuItem("Selection Method", tabName ='dad'),
      menuItem("Best Model Selection", tabName = "bm"),
      menuItem("Customer Prediction data", tabName = "cpa"),
      menuItem("Raw Data",tabName = "RawData")
    )),
    dashboardBody(
      tabItems(
        tabItem(tabName = "General",
                fluidRow(tags$img(src="project.png"))),
        tabItem(tabName = "dashboard", 
               fluidRow(   
                  box(plotOutput("histogram")),
                  sliderInput("bins","Number of bins",1,100,10),
          box(plotOutput("histogram1")),
          box(plotOutput("histogram2")),
          box(plotOutput("histogram3")),
          box(plotOutput("histogram4")),
          box(plotOutput("histogram5")),
          box(plotOutput("histogram6")),
          box(plotOutput("histogram7")),
          box(plotOutput("histogram8")),
          box(plotOutput("histogram9")),
          box(plotOutput("histogram10")),
          box(plotOutput("histogram11")),
          box(plotOutput("histogram12")),
          box(plotOutput("histogram13")),
          box(plotOutput("histogram14")),
          box(plotOutput("histogram15")),
          box(plotOutput("histogram16")),
          #box(plotOutput("histogram17")),
         # box(plotOutput("histogram18")),
          sliderInput("bw","Binwidth",1,100,10)
          
      )),
     tabItem(tabName = "diagram", h1("Coorelation and Plots"),
             fluidRow(box(width = 7,"This pie-chart depicts that about a one-quater of our teleco-customer
                                      have churned within the last month while more than a three-quater is
                                      has not churned.")),
             fluidRow(box(width = 7,tags$img(src="piechart.png",height = 300, width = 450))),
             fluidRow(box(width = 7,"The median tenure for customers who have churned is around
                          10 months and that of those who have not churned is approximately 40 months. 
                          Also, from the size of the box plots we can see that the number of churned 
                          people is less as compared to those who have not churned.")),
             fluidRow(box(width = 7,tags$img(src="tenurechurn.png",height = 300, width = 650))),
             fluidRow(box(width = 7,"The median of customers who have churned, below 1250, are people
                          with low total charges and the median of the customers who have not churned
                          is above 1250.")),
             fluidRow(box(width = 7,tags$img(src="totalchargeschurn.png",height = 300, width = 650))),
             fluidRow(box(width = 7," The Total Charges has positive correlation with Monthly Charges
                          and tenure. There is little or no relation between Monthly Charges and tenure")),
             fluidRow(box(width = 7,tags$img(src="correlationmatrix.png",height = 300, width = 650)))),
      tabItem(tabName = "cost", 
              fluidRow(tags$img(src="Capture.png"))),
      tabItem(tabName = "Model1",h1("Logistic Regression."),
              fluidRow(
                box(title = "With Probability > 0.5", status = "warning",solidHeader = T, tableOutput('mydata')),
                 box(title = "With Probability > 0.6", status = "primary",solidHeader = T,tableOutput('mydata2')),
                 box(title = "With Probability > 0.7",status = "primary",solidHeader = T,tableOutput('mydata3')),
               #  box(title = "With Probability > 0.8",status = "primary",solidHeader = T,tableOutput('mydata4')),
                box(title = "With Probability > 0.4",status = "primary",solidHeader = T,tableOutput('mydata5')),
                box(title = "With Probability > 0.5 -Using selection predictors ",status = "warning",solidHeader = T,tableOutput('mydata6'))
                
              )),
      tabItem(tabName = "Model2",h1("K Nearest Neighbors"),
              fluidRow(
                box(title = "With K = 1", status = "primary",solidHeader = T, tableOutput('knn1')),
                box(title = "With K = 5", status = "primary",solidHeader = T,tableOutput('knn2')),
                box(title = "With K = 10",status = "warning",solidHeader = T,tableOutput('knn3')),
                box(title = "With K = 15",status = "primary",solidHeader = T,tableOutput('knn4')),
                box(title = "With K = 21",status = "primary",solidHeader = T,tableOutput('knn5'))
                
                
              )
              ),
      tabItem(tabName = "RawData",
              fluidRow(
                tableOutput('datashyam')
              )
            ),
    tabItem(tabName = "Model3",h1("Tree Based Method"),
            fluidRow(box(width = 20,"History of Decision Trees. In computer science, Decision tree learning uses a decision tree (as a predictive model) to go 
                     from observations about an item (represented in the branches) 
                     to conclusions about the item's target value (represented in the leaves).
                     It is one of the predictive modeling approaches used in statistics, data mining and machine learning. 
                     Tree models where the target variable can take a discrete set of values are called classification trees;
                     in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. 
                     Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees."),
                     box(width = 5,tags$img(src="meme2.png",height = 400, width = 400)),
                     box(width = 5,tags$img(src="meme3.jpg", height = 400, width = 400))
                     )),
    tabItem(tabName = "Model3a",h1("Decision Trees"),
            fluidRow(
              box(title = "Decision Tree Confusion Matrix", status = "primary", solidHeader = T, tableOutput('dt')),
              box(title = "Decision Tree Confusion Matrix-Using Selection predictors", status = "warning", solidHeader = T, tableOutput('dt_selc'))
            )),
    tabItem(tabName = "Model3b",h1("Random Forest"),      
            fluidRow(
              box(title = " Random Forest Confusion Matrix", status ="primary", solidHeader = T, tableOutput('rf')),
              box(title = " Random Forest Confusion Matrix-Using Selection predictors", status ="warning", solidHeader = T, tableOutput('rf_selc')))),
    tabItem(tabName = "Model4",h1("Discriminant Analysis"),
            fluidRow(box(width = 20 ,"Discriminant Analysis (DA) is a multivariate classification technique that separates objects into two or more mutually exclusive groups based
on measurable features of those objects. The measurable features are sometimes called predictors or independent variables, while the classification
                         group is the response or what is being predicted.
                         
                         DA uses data where the classes are known beforehand to create a model that may be used to predict future observations. It's useful as an analytic
                         technique trying to understand the relationship between independent variables and a discrete dependent variable. It differs from regression analysis
                         in that the dependent variable must be discrete.It differs from cluster analysis in that the classes must be known beforehand to create the model.")
                     
            )),
    tabItem(tabName = "Model4a",h1("LDA"),
            fluidRow(box(title = "LDA confusion matrix", status = "primary",solidHeader = T, tableOutput('ldatable')),
                     box(title = "LDA confusion matrix-Using Selection predictorsn", status = "warning",solidHeader = T, tableOutput('ldatable_selc')))),
    tabItem(tabName = "Model4b",h1("QDA"),
            fluidRow(box(title = "QDA confusion matrix", status = "primary",solidHeader = T, tableOutput('qdatable')),
                     box(title = "QDA confusion matrix-Using Selection predictors", status = "warning",solidHeader = T, tableOutput('qdatable_selc')))),
    tabItem(tabName = "Model5",h1("Naive Bayes"),
            fluidRow(box(title = "Naive Bayes Confusion matrix", status = "primary", solidHeader = T,tableOutput('naive')),
                     box(title = "Naive Bayes Confusion matrix-Using Selection predictors", status = "warning", solidHeader = T,tableOutput('naive_selc')))),
    tabItem(tabName = "dr", h1("Dimensionality Reduction"), 
           fluidRow(box(width = 20,"The process of reducing the number of random variables under consideration 
           by obtaining a set of principal variables. It can be divided into feature selection and feature extraction."),
                    box(tags$img(src="dr.jpg", width = 500)))),
    tabItem(tabName = "dad", h1("Selection Method"), 
            fluidRow(box(width = 20,"We have used the Forward and the Backward selection methods in order to find out the significant
                         predictors in the dataset. We could see in the below table that 6 predictors are returned by the forward selection
                         method and 7 predictors are returned from the Backward selection . So we chose a mixture of the significant
                         predictors returned from both the forward and backward selection methods as our optimal predictor list and built
                         the models."),
                     fluidRow(box(width = 12,tags$img(src="selection.png",height = 500, width = 850))))),
      tabItem(tabName = "bm", h1("Selecting the best Model"),
            fluidRow(box(width = 12,tags$img(src="QDA.png",height = 300, width = 850)))),
    tabItem(tabName = "cpa", h1("Customer's predicted to churn"),
            fluidRow(tableOutput('teleco_final')))
      
      )
  )
)
)

  
